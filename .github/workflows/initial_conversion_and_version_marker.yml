# .github/workflows/initial_conversion_and_version_marker.yml
name: Initial Conversion and Version Marker

on:
  push:
    paths:
      - 'conversation/csv/scanning.xlsx' # Trigger when scanning.xlsx changes
      - 'conversation/csv/prices.xlsx'    # Trigger when prices.xlsx changes

jobs:
  initial_conversion:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Create Log Entry for Initial Conversion Check
        run: |
          mkdir -p conversation/Logs
          echo "$(date +"%Y-%m-%d %H:%M:%S") - Initial conversion check triggered by file push." >> conversation/Logs/workflow_activity.log
          git config user.name "github-actions"
          git config user.email "actions@github.com"
          git add conversation/Logs/workflow_activity.log
          git commit -m "Log: Initial conversion check initiated." || echo "No new log entry commit."
          git push || echo "Log push failed."

      - name: Verify both actual data files exist before initial conversion
        id: check_files
        run: |
          SCANNING_FILE="conversation/csv/scanning.xlsx"
          PRICES_FILE="conversation/csv/prices.xlsx"
          
          if [ -f "$SCANNING_FILE" ] && [ -f "$PRICES_FILE" ]; then
            echo "Both scanning.xlsx and prices.xlsx found. Proceeding with initial conversion."
            echo "both_files_exist=true" >> "$GITHUB_OUTPUT"
          else
            echo "One or both Excel files missing. Skipping initial conversion."
            echo "both_files_exist=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Set up Python for Initial Conversion
        if: steps.check_files.outputs.both_files_exist == 'true'
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install Required Python Packages for Initial Conversion
        if: steps.check_files.outputs.both_files_exist == 'true'
        run: pip install pandas openpyxl sqlite-utils

      - name: Run Phase 1 Conversion and Create version.txt
        if: steps.check_files.outputs.both_files_exist == 'true'
        run: |
          python3 <<EOF
          import pandas as pd
          import sqlite3
          import os
          from datetime import datetime
          import traceback
          import sys # Import sys for sys.exit

          try:
              scan_file = "conversation/csv/scanning.xlsx"
              price_file = "conversation/csv/prices.xlsx"
              
              os.makedirs("conversation/Temp", exist_ok=True)
              log_path = "conversation/Logs/workflow_activity.log" # Log to the central activity log

              with open(log_path, "a") as logfile:
                  now = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
                  logfile.write(f"{now} Phase 1 Conversion Started: Merging Excel files.\n")

              scan_df = pd.read_excel(scan_file)
              price_df = pd.read_excel(price_file)

              price_df["OriginalPrice"] = pd.to_numeric(price_df["OriginalPrice"], errors='coerce')
              price_df = price_df[["Barcode", "OriginalPrice"]]

              merged_df = pd.merge(scan_df, price_df, on="Barcode", how="left")

              merged_df["OriginalPrice"] = merged_df["OriginalPrice"].apply(
                  lambda x: str(int(x)) if pd.notna(x) and x == int(x) else ('' if pd.isna(x) else str(x))
              )

              final_columns = ["Barcode", "Article", "Percentage", "OriginalPrice"]
              merged_df = merged_df[final_columns]

              db_name_temp = "conversation/Temp/temp_conversion.db"
              conn = sqlite3.connect(db_name_temp)
              merged_df.to_sql("sc", conn, if_exists="replace", index=False, dtype={'OriginalPrice': 'TEXT'})
              conn.commit()
              conn.close()

              # Create the version.txt marker file
              version_file_path = "conversation/Temp/version.txt"
              timestamp_for_version = datetime.now().strftime("%Y%m%d_%H%M%S")
              with open(version_file_path, 'w') as f:
                  f.write(f"Conversion_Done_{timestamp_for_version}\n")
              
              with open(log_path, "a") as logfile:
                  now = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
                  logfile.write(f"{now} Phase 1 Complete. Temporary DB created. Version marker file ({version_file_path}) created.\n")

          except Exception as e:
              log_path_error = "conversation/Logs/workflow_activity.log"
              with open(log_path_error, "a") as logfile:
                  now = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
                  logfile.write(f"{now} ERROR: Phase 1 Conversion Failed: {str(e)}\n")
                  logfile.write(traceback.format_exc())
              sys.exit(1) # Fail the job if conversion fails
          EOF
        env:
          PYTHONUNBUFFERED: 1 # Ensure Python output is unbuffered for real-time logs

      - name: Upload conversion artifacts (temp_conversion.db and version.txt)
        if: steps.check_files.outputs.both_files_exist == 'true'
        uses: actions/upload-artifact@v3
        with:
          name: conversion-data
          path: |
            conversation/Temp/temp_conversion.db
            conversation/Temp/version.txt
          retention-days: 1 # Keep artifact for 1 day (or adjust as needed)
